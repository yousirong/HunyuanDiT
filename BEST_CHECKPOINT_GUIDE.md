# Best Checkpoint Tracking Guide

ì´ ê°€ì´ë“œëŠ” HunyuanDiT í›ˆë ¨ ì¤‘ì— ìë™ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì¶”ì í•˜ê³  ì €ì¥í•˜ëŠ” ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸŒŸ ìƒˆë¡œìš´ ê¸°ëŠ¥

### ìë™ ì„±ëŠ¥ í‰ê°€
- **CLIP Score**: í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì¼ì¹˜ë„ ì¸¡ì •
- **LPIPS**: ì§€ê°ì  ì´ë¯¸ì§€ ìœ ì‚¬ì„± ì¸¡ì •
- **Inception Score**: ì´ë¯¸ì§€ í’ˆì§ˆê³¼ ë‹¤ì–‘ì„± ì¸¡ì •
- **FID**: Frechet Inception Distance (ì°¸ì¡° ì´ë¯¸ì§€ê°€ ìˆì„ ë•Œ)
- **Composite Score**: ëª¨ë“  ë©”íŠ¸ë¦­ì„ ì¢…í•©í•œ ì ìˆ˜

### ìë™ Best ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
- ë§¤ 2ë²ˆì§¸ ì²´í¬í¬ì¸íŠ¸ë§ˆë‹¤ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰
- ìƒìœ„ 3ê°œ ì²´í¬í¬ì¸íŠ¸ ìë™ ìœ ì§€
- `best.pt` ì‹¬ë³¼ë¦­ ë§í¬ ìë™ ì—…ë°ì´íŠ¸
- ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ìë™ ì •ë¦¬ (ë§¤ 10k ìŠ¤í…ë§ˆë‹¤ í•˜ë‚˜ì”© ë³´ì¡´)

## ğŸ“¦ ì„¤ì¹˜

í‰ê°€ ë©”íŠ¸ë¦­ì„ ìœ„í•œ ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜:

```bash
# í‰ê°€ìš© íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements_evaluation.txt

# ë˜ëŠ” ê°œë³„ ì„¤ì¹˜
pip install lpips clip-by-openai pytorch-fid scipy scikit-image
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

ê¸°ì¡´ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ best checkpoint trackingì´ ì‘ë™í•©ë‹ˆë‹¤:

```bash
# ê¸°ë³¸ í›ˆë ¨ (ìë™ í‰ê°€ í¬í•¨)
./scripts/train_waymo_base.sh

# ë˜ëŠ” ì§ì ‘ ì‹¤í–‰
python hydit/train_deepspeed.py \
    --model DiT-g/2 \
    --task-flag waymo_training \
    # ... ê¸°íƒ€ ì˜µì…˜ë“¤
```

## ğŸ“Š ì¶œë ¥ ê²°ê³¼

### í›ˆë ¨ ì¤‘ ë¡œê·¸ ì˜ˆì‹œ
```
[Step 2000] Evaluating model performance at step 2000
ğŸ† New best checkpoint! Score: 0.7245
=== Best Checkpoint Summary ===
Tracking metric: composite_score
Saved checkpoints: 3/3
  #1: Step 2000, Epoch 15
      Path: 0002000.pt
      Metrics: clip_score: 0.8123, lpips: 0.1234, inception_score: 3.45, composite_score: 0.7245
  #2: Step 1600, Epoch 12
      ...
================================
```

### ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤

#### ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ:
- `best.pt` - ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ë¡œì˜ ì‹¬ë³¼ë¦­ ë§í¬
- `best_checkpoints.json` - Best ì²´í¬í¬ì¸íŠ¸ ì¶”ì  ìƒíƒœ
- `best_checkpoint_results.json` - ìµœì¢… ê²°ê³¼ ìš”ì•½

#### ì‹¤í—˜ ë””ë ‰í† ë¦¬ì—ì„œ:
- `evaluation_samples/` - í‰ê°€ìš© ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤
  - `eval_generated_XXX.jpg` - ìƒì„±ëœ ì´ë¯¸ì§€
  - `eval_comparison_XXX.jpg` - ì›ë³¸-ìƒì„± ë¹„êµ ì´ë¯¸ì§€
  - `eval_prompt_XXX.txt` - ì‚¬ìš©ëœ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸

## ğŸ”§ ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§•

### Best Tracker ì„¤ì • ë³€ê²½

`hydit/train_deepspeed.py`ì—ì„œ ì„¤ì •ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# Best Checkpoint Tracker ì´ˆê¸°í™” ë¶€ë¶„
best_tracker = BestCheckpointTracker(
    checkpoint_dir=checkpoint_dir,
    metric_name='composite_score',  # ì¶”ì í•  ë©”íŠ¸ë¦­ ë³€ê²½
    higher_is_better=True,          # ì ìˆ˜ ë°©í–¥
    save_top_k=3                    # ìœ ì§€í•  ì²´í¬í¬ì¸íŠ¸ ìˆ˜
)
```

### í‰ê°€ ë¹ˆë„ ì¡°ì •

```python
# save_checkpoint í•¨ìˆ˜ ë‚´ë¶€
if by != "final" and train_steps % (args.ckpt_every * 2) == 0:  # ë§¤ 2ë²ˆì§¸ ì²´í¬í¬ì¸íŠ¸
    # í‰ê°€ ë¹ˆë„ë¥¼ ë³€ê²½í•˜ë ¤ë©´ ì´ ì¡°ê±´ì„ ìˆ˜ì •
    # ì˜ˆ: args.ckpt_every * 1 (ë§¤ë²ˆ), args.ckpt_every * 4 (4ë²ˆì— 1ë²ˆ)
```

### ì‚¬ìš©í•  ë©”íŠ¸ë¦­ ì„ íƒ

ì£¼ìš” ë©”íŠ¸ë¦­ë³„ íŠ¹ì§•:

- **`composite_score`**: ëª¨ë“  ë©”íŠ¸ë¦­ì„ ì¢…í•© (ê¶Œì¥)
- **`clip_score`**: í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì¼ì¹˜ë„ë§Œ ê³ ë ¤
- **`inception_score`**: ì´ë¯¸ì§€ í’ˆì§ˆê³¼ ë‹¤ì–‘ì„±ë§Œ ê³ ë ¤
- **`lpips`**: ì§€ê°ì  ìœ ì‚¬ì„± (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ, `higher_is_better=False`)
- **`fid`**: Frechet Inception Distance (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ, `higher_is_better=False`)

## ğŸ“ˆ í‰ê°€ ë©”íŠ¸ë¦­ ì´í•´í•˜ê¸°

### CLIP Score (0.0 ~ 1.0)
- **0.8+**: í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ê°€ ë§¤ìš° ì˜ ì¼ì¹˜
- **0.6-0.8**: ì ì ˆí•œ ì¼ì¹˜ë„
- **0.6 ë¯¸ë§Œ**: ì¼ì¹˜ë„ê°€ ë‚®ìŒ

### LPIPS (0.0 ~ 2.0+)
- **0.0-0.2**: ë§¤ìš° ìœ ì‚¬ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
- **0.2-0.5**: ì ë‹¹íˆ ìœ ì‚¬
- **0.5+**: í° ì°¨ì´

### Inception Score (1.0+)
- **5.0+**: ë§¤ìš° ì¢‹ì€ í’ˆì§ˆ
- **3.0-5.0**: ì ì ˆí•œ í’ˆì§ˆ
- **3.0 ë¯¸ë§Œ**: ê°œì„  í•„ìš”

### Composite Score
- ëª¨ë“  ë©”íŠ¸ë¦­ì„ ê°€ì¤‘í‰ê· í•œ ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
- ê°€ì¤‘ì¹˜: CLIP Score (40%), IS (30%), LPIPS (-20%), FID (-10%)

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### í‰ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì˜¤ë¥˜
```bash
# CLIP ì„¤ì¹˜ ë¬¸ì œ
pip install git+https://github.com/openai/CLIP.git

# FID ì„¤ì¹˜ ë¬¸ì œ  
pip install clean-fid

# LPIPS ì„¤ì¹˜ ë¬¸ì œ
pip install lpips
```

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
í‰ê°€ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ë ¤ë©´:

```python
# evaluation_sampling.pyì—ì„œ num_evaluation_samples ì¤„ì´ê¸°
num_evaluation_samples=10,  # ê¸°ë³¸ê°’ 20ì—ì„œ 10ìœ¼ë¡œ ì¤„ì„
```

### í‰ê°€ ë¹„í™œì„±í™”
í‰ê°€ ì—†ì´ í›ˆë ¨í•˜ë ¤ë©´:

```python
# save_checkpoint í•¨ìˆ˜ì—ì„œ í‰ê°€ ì¡°ê±´ì„ Falseë¡œ ì„¤ì •
if False:  # by != "final" and train_steps % (args.ckpt_every * 2) == 0:
    # í‰ê°€ ì½”ë“œ...
```

## ğŸ“Š TensorBoard í†µí•©

Best checkpoint ì •ë³´ë„ TensorBoardì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
tensorboard --logdir results/waymo_base/001-DiT-g-2/tensorboard_logs
```

ë‹¤ìŒ ë©”íŠ¸ë¦­ë“¤ì´ ì¶”ê°€ë¡œ ê¸°ë¡ë©ë‹ˆë‹¤:
- `Evaluation/CLIP_Score`
- `Evaluation/LPIPS`
- `Evaluation/Inception_Score`
- `Evaluation/FID`
- `Evaluation/Composite_Score`
- `Evaluation/IsBest` (ìƒˆë¡œìš´ bestì¸ì§€ ì—¬ë¶€)

## ğŸ¯ ìµœì  í™œìš©ë²•

1. **í›ˆë ¨ ì´ˆê¸°**: Composite scoreë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì „ë°˜ì ì¸ ì„±ëŠ¥ í–¥ìƒ í™•ì¸
2. **í›ˆë ¨ ì¤‘ê¸°**: íŠ¹ì • ë©”íŠ¸ë¦­(ì˜ˆ: CLIP score)ì— ì§‘ì¤‘í•˜ì—¬ í…ìŠ¤íŠ¸ ì¼ì¹˜ë„ ê°œì„ 
3. **í›ˆë ¨ í›„ê¸°**: Best ì²´í¬í¬ì¸íŠ¸ë“¤ë¡œ ì¶”ê°€ í‰ê°€ ë° ì„ íƒ

## ğŸ“ ì‚¬ìš©ì ì •ì˜ ë©”íŠ¸ë¦­

ìƒˆë¡œìš´ í‰ê°€ ë©”íŠ¸ë¦­ì„ ì¶”ê°€í•˜ë ¤ë©´:

1. `hydit/evaluation_metrics.py`ì— ë©”íŠ¸ë¦­ í•¨ìˆ˜ ì¶”ê°€
2. `evaluate_sample_quality` ë©”ì„œë“œì— í†µí•©
3. `best_checkpoint_tracker.py`ì—ì„œ ê°€ì¤‘ì¹˜ ì„¤ì •

ì˜ˆì‹œ:
```python
# evaluation_metrics.pyì— ìƒˆ ë©”íŠ¸ë¦­ ì¶”ê°€
def calculate_custom_metric(self, images):
    # ì‚¬ìš©ì ì •ì˜ ë©”íŠ¸ë¦­ ê³„ì‚°
    return score

# evaluate_sample_qualityì— í†µí•©  
metrics['custom_metric'] = self.calculate_custom_metric(generated_images)
```

ì´ì œ í›ˆë ¨ì„ ì‹œì‘í•˜ë©´ ìë™ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ì˜ ëª¨ë¸ì´ `best.pt`ë¡œ ì €ì¥ë©ë‹ˆë‹¤! ğŸš€